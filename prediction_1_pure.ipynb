{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/ShoaibSajid/Python_CNN/blob/main/CNN_Python.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I-725DWZTpo6"
   },
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "\n",
    "from logging import raiseExceptions\n",
    "import os\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "# import mnist\n",
    "import numpy as np\n",
    "from conv import Conv3x3, Conv3x3_n_to_n_padding, Conv3x3_1_to_n_padding\n",
    "from maxpool import MaxPool2\n",
    "from softmax import Softmax\n",
    "from relu import Relu\n",
    "from softmax_test import Softmax_test\n",
    "from fc import FC\n",
    "\n",
    "# Define settings for run\n",
    "\n",
    "debug=False\n",
    "\n",
    "shuffle_data=False\n",
    "\n",
    "run_train=True\n",
    "run_val=True\n",
    "\n",
    "load_saved_weights=False\n",
    "weight_file='weights/best_99.pkl'\n",
    "\n",
    "total_epoch=100\n",
    "training_acc_internal=1000\n",
    "\n",
    "# Initialize the network layers\n",
    "\n",
    "conv0   = Conv3x3_1_to_n_padding( output=8                        )     # 28x28x1   -> 28x28x8  (Convolution with 8 filters)\n",
    "pool0   = MaxPool2              (                                 )     # 28x28x8   -> 14x14x8  (MaxPooling 2x2)\n",
    "conv1   = Conv3x3_n_to_n_padding( output=16     ,   input=8       )     # 14x14x8   -> 14x14x16 (Convolution with 8 filters)\n",
    "pool1   = MaxPool2              (                                 )     # 14x14x16  -> 07x07x16 (MaxPooling 2x2)\n",
    "# conv2   = Conv3x3_n_to_n_padding( output=32     ,   input=16      )\n",
    "# conv3   = Conv3x3_n_to_n_padding( output=64     ,   input=32      )\n",
    "fc0     = FC                    ( 7 * 7 * 16  ,   7 * 7 * 16      )     # 784       -> 784      (FC)\n",
    "fc1     = FC                    ( 7 * 7 * 16  ,   10              )     # 784       -> 10       (FC)\n",
    "softmax = Softmax               (                                 )     # 13x13x8   -> 10       (Softmax)\n",
    "relu    = Relu                  (                                 )     # 13x13x8   -> 10       (Softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "I-725DWZTpo6"
   },
   "outputs": [],
   "source": [
    "# Defining the network - Forward propagation\n",
    "def forward(im, label='noneed', debug=False):\n",
    "    im        = (im / 255) - 0.5\n",
    "\n",
    "    # Conv 0 with Pool\n",
    "    out_conv0 = conv0.forward   ( im            )\n",
    "    out_pool0 = pool0.forward   ( out_conv0     )\n",
    "\n",
    "    # Conv 1 with Pool\n",
    "    out_conv1 = conv1.forward   ( out_pool0     )\n",
    "    out_pool1 = pool1.forward   ( out_conv1     )\n",
    "\n",
    "    # Swap axes to realign for flattening\n",
    "    out_pool2 = np.swapaxes(out_pool1,0,2)\n",
    "    out_pool3 = np.swapaxes(out_pool2,1,2)\n",
    "\n",
    "    # FC0 and Relu\n",
    "    out_fc0   = fc0.forward     ( out_pool3     )\n",
    "\n",
    "    # FC1 and SoftMax\n",
    "    out_fc1   = fc1.forward     ( out_fc0       )\n",
    "    out_soft  = softmax.forward ( out_fc1       )\n",
    "\n",
    "    if debug:\n",
    "        print(f\"Input Image: {im[-4]}\\n\")\n",
    "        print(f\"x_conv0 filters : {conv0.filters[0]}\\n\")\n",
    "        print(f\"x_conv0 : {out_conv0[:,:,0][-1]}\\n\")\n",
    "        print(f\"MaxPool0: {out_pool0[:,:,0][-1]}\\n\")\n",
    "        print(f\"x_conv1 filters : {conv1.filters[0,:,:,0]}\\n\")\n",
    "        print(f\"x_conv1 : {out_conv1[:,:,0][-1]}\\n\")\n",
    "        print(f\"MaxPool1: {out_pool1[:,:,0][-1]}\\n\")\n",
    "        print(f\"FC0 Weights: {fc0.weights[:,0][:10]}\\n\")\n",
    "        print(f\"FC0 output: {out_fc0[:10]}\\n\")\n",
    "        print(f\"FC1 Weights: {fc1.weights[:,0][:10]}\\n\")\n",
    "        print(f\"FC1 output: {out_fc1[:10]}\\n\")\n",
    "        print(f\"SoftMax output: {out_soft}\\n\")\n",
    "\n",
    "    return out_soft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "I-725DWZTpo6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loading weights from weights/best_99.pkl file. LR restored to 0.0005. Last Accuracy 99%\n"
     ]
    }
   ],
   "source": [
    "def load_weights(name):\n",
    "  if os.path.isfile(name): \n",
    "    weight_file = open(str(name), \"rb\")\n",
    "    weights = pickle.load(weight_file)\n",
    "    conv0.filters  = weights[\"conv0\"]      \n",
    "    conv1.filters  = weights[\"conv1\"]      \n",
    "    fc0.weights    = weights[\"fc0_weights\"]\n",
    "    fc0.biases     = weights[\"fc0_biases\" ]\n",
    "    fc1.weights    = weights[\"fc1_weights\"]\n",
    "    fc1.biases     = weights[\"fc1_biases\" ]\n",
    "    lr             = weights[\"lr\" ]\n",
    "    max_acc        = weights[\"max_acc\"]\n",
    "    print(f\"\\nLoading weights from {name} file. LR restored to {lr}. Last Accuracy {max_acc}%\")\n",
    "    return lr, max_acc\n",
    "  else:\n",
    "    print(\"Weights file not found.\")\n",
    "    lr=0.005\n",
    "    max_acc=0\n",
    "    return lr, max_acc\n",
    "   \n",
    "\n",
    "lr, max_acc = load_weights(weight_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load samples from MNIST test dataset\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, ToPILImage\n",
    "\n",
    "data_folder = '../MNIST'\n",
    "tedt = datasets.MNIST(\n",
    "    root=data_folder,\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor(),\n",
    ")\n",
    "\n",
    "tedl = DataLoader(tedt, batch_size=1)\n",
    "\n",
    "trit = iter(tedl)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y = next(trit)\n",
    "\n",
    "# tensor(0-1) > pil(0-255) > np(0-255)\n",
    "topil = torchvision.transforms.ToPILImage()\n",
    "x = x.reshape(1,28,28)\n",
    "\n",
    "xpil = topil(x)\n",
    "xnp  = np.array(xpil)\n",
    "\n",
    "pre = forward(xnp).argmax()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 7 gt tensor([7])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAxUlEQVR4nGNgGDaAEUKFpD77sfTFHeyS9xQYGBg+X4UKPuk6w8DAwMDAAuGm6l/TMnSweCzLwPDntSTDozPIOhkYGBgYBA3PmDIw/Lh1XShnGi5nBP+9KIRLTuzl/2AokwlDMlv0/U1cGq1//rPDJcfQ+m83Ky45zrM/rHBqrPu3Daec9+8PlrjkhO/+W4ZLjvn0v9vKuCTV/v3zxSUn/+BfMSMuydZ//0xwydl+QpdEClsbHoa7X1AkWZA5F53f4TIWEwAAaRE8kJuHrgAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FACC5B80DD8>"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('prediction',pre, 'gt',y)\n",
    "xpil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 2 gt tensor([2])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA6ElEQVR4nGNgoAlgRDBLOPVCGKYfX4xN2cq/f//+/fv3lhwOuat9G/7+rcKUM/n195ICDwPbub89mJK+vy9JMjAwVP3464jFWHkhBgYGhot/sUoyMDAwMJR+/3uMC4ecz/e/z+2R+EwormJjWHkQh8YN3/7O58EhJ/nq70tlXK459vdvLy45vx9/9+IyVPgEHo1tf/+uxaWR4cffv5LoYixIbKHfDAwMH3+z8jMIFjIw/C3/hix5iYGBgWH1c/FwCPdFKzwlrPNHqPrzj2HTGYYjxxHJpIyVgUE7nIFh3gOGdddxuWyAAQCfcVM+FkfDOQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FACC5B8E128>"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('prediction',pre, 'gt',y)\n",
    "xpil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 1 gt tensor([1])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAiElEQVR4nGNgGARA7V8unM2ELmn47ylune0fccvpfpmG4KAbq861ErfOU/e5ccop/LuBxEMz1p7hNW5JXYYunKZavj3LgVOns9CNHzgl9f+vwWmqxIvrKHwUnQliJ3BLyjO8x2kqw5N/Tjh12orj1sfQ++8sMy6dXF4Ma/7i0sh6bAMXHnPpBAAPgx/ARH1j7wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FACC5B8E470>"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('prediction',pre, 'gt',y)\n",
    "xpil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 0 gt tensor([0])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA70lEQVR4nMXQsWoCQRQF0JvBNNrGdjcgIR8gJJVrqRZCfkMkgn+QlEIIAcHaHzClVWySJkmXSgxqIbKCbcrLxRSbNe7M2uqr7syZefAecOTK9fTp78MLUs2ds9nJ+b71OPMfWzdXAALz9ZrSVCQpclp0bbiRpPVckmPlmUh268Ed2bDsfEVx2skCfsif9qkzxcsZAOCWYsHGDy+K/nuM2zmNuV5E6cQYc5/4+UDG0W07iTFfXlGhl45PJGelKGeQrOElgPFb8vJbqtWW0kYpG2qT8W7ZtdEP/zAcFbI2IniMsOkIAKD6zEGl6qXjweoXXfV/5XmKZEMAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FACC5B8E4A8>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('prediction',pre, 'gt',y)\n",
    "xpil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 4 gt tensor([4])\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAA2klEQVR4nGNgGLzA6AGU4SYLZTAhJN3ZoQy/bgxJFi8Y64wWN7qko+V8KEtIiwvNRt03N3mgzAN/RNEkV3w3hWn8/xdNMuTTZRiz9+9eVlTJlX+yoCyFF7+cUOX4H/6BMdv+wM2AupZdegVMRJnhCppzOM9cFIKwxP7+zYaJskCo73eDt/YxMDDoKMv/Z/iPppNBc9XXP3/+/Hnx/PefP5wwQUa4tKEyAwPDGoaF0TDTsID6P3900exEAEZGhss4Jf8jOYcJXZKD4QdOKxlevMnHLbnZCbcclQAA/k48Hcv/z+EAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=28x28 at 0x7FACC5B8E5F8>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('prediction',pre, 'gt',y)\n",
    "xpil"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "provenance": []
  },
  "kernelspec": {
   "display_name": "torch0",
   "language": "python",
   "name": "torch0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "4fbbc6560802a9753d76c1864ab18e70962bbfcb64c614d1799210197ece64ee"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
